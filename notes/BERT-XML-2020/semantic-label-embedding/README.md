# Semantic label embeddings

[Frome, A., Corrado, G. S., Shlens, J., Bengio, S., Dean, J., Ranzato, M. A., & Mikolov, T. (2013). Devise: A deep visual-semantic embedding model. Advances in neural information processing systems, 26.](https://proceedings.neurips.cc/paper/2013/file/7cce53cf90577442771720a370c3c723-Paper.pdf)
- [fg91/DeViSE-zero-shot-classification: DeViSE model (zero-shot learning) ](https://github.com/fg91/DeViSE-zero-shot-classification)


[Cao, X., Zhang, H., Guo, X., Liu, S., & Meng, D. (2015). SLED: semantic label embedding dictionary representation for multilabel image annotation. IEEE Transactions on Image Processing, 24(9), 2746-2759.](https://pubmed.ncbi.nlm.nih.gov/25935037/)


[Pappas, N., & Henderson, J. (2019). Gile: A generalized input-label embedding for text classification. Transactions of the Association for Computational Linguistics, 7, 139-155.](https://aclanthology.org/Q19-1009/)
- [idiap/gile: A generalized input-label embedding for text classification](https://github.com/idiap/gile)


# Related works: Extreme Multi-label classification (XMC)

[Sen, C., Ye, B., Aslam, J., & Tahmasebi, A. (2021). From Extreme Multi-label to Multi-class: A Hierarchical Approach for Automated ICD-10 Coding Using Phrase-level Attention. arXiv preprint arXiv:2102.09136.](https://arxiv.org/abs/2102.09136)


[Zhang, J., Chang, W. C., Yu, H. F., & Dhillon, I. (2021). Fast multi-resolution transformer fine-tuning for extreme multi-label text classification. Advances in Neural Information Processing Systems, 34. ](https://arxiv.org/abs/2110.00685)


[Chang, W. C., Yu, H. F., Zhong, K., Yang, Y., & Dhillon, I. (2019). X-bert: extreme multi-label text classification with using bidirectional encoder representations from transformers. arXiv preprint arXiv:1905.02331.](https://assets.amazon.science/e3/f2/2ec101df490caf28a3e596289a53/x-bert-extreme-multi-label-text-classification-using-bidirectional-encoder-representations-from-transformers.pdf)
- [guoqunabc/X-BERT: X-BERT: eXtreme Multi-label Text Classification with BERT](https://github.com/guoqunabc/X-BERT)

[Chang, W. C., Yu, H. F., Zhong, K., Yang, Y., & Dhillon, I. S. (2020, August). Taming pretrained transformers for extreme multi-label text classification. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 3163-3171).](https://arxiv.org/pdf/1905.02331.pdf)
- [OctoberChang/X-Transformer](https://github.com/OctoberChang/X-Transformer)
- [amzn/pecos: PECOS - Prediction for Enormous and Correlated Spaces](https://github.com/amzn/pecos)


